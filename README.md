This is an implementation in formal evaluation of various NLP/LLM models in measuring fairness and interpretability among several metrics. Completed for CS378: Trustworthy Machine Learning in Fall 2023.

The project features:

- Deployment of prompting text continuations from the GPT-2 model by OpenAI on Huggingface
- Measuring fairness in GPT-2 through toxicity, regard, and HONEST score (please see comments in respective programs for particular research studies referenced)
- Assessing adversarial exploitability of the Inception V3 Image Classification model
- Implementation of four FGSM variants to perturb image tensor inputs for desired label image classification
- Samples and artifacts of LLM / classification outputs in program execution

This repository is not to be copied or reconstructed in any way, shape, or form for non-research purposes. Please contact me for any requested modifications.
